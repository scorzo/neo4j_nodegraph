{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Powered Consultancy Graph Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. Configuration\n",
    "2. Helper Functions\n",
    "3. Prompts\n",
    "4. Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from string import Template\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API configuration\n",
    "openai.api_type = \"\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai_deployment = \"chat-gpt35\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j configuration & constraints\n",
    "neo4j_url = os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USER\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "gds = GraphDatabase.driver(neo4j_url, auth=(neo4j_user, neo4j_password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to call the OpenAI API\n",
    "def process_gpt(file_prompt, system_msg):\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": file_prompt},\n",
    "        ],\n",
    "    )\n",
    "    nlp_results = completion.choices[0].message.content\n",
    "    sleep(8)\n",
    "    return nlp_results\n",
    "\n",
    "\n",
    "# Function to take folder of files and a prompt template, and return a json-object of all the entities and relationships\n",
    "def extract_entities_relationships(folder, prompt_template):\n",
    "    start = timer()\n",
    "    files = glob.glob(f\"./data/{folder}/*\")\n",
    "    system_msg = \"You are a helpful IT-project expert who extracts information from documents.\"\n",
    "    print(f\"Running pipeline for {len(files)} files in {folder} folder\")\n",
    "    results = []\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"Extracting entities and relationships for {file}\")\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                text = f.read().rstrip()\n",
    "                prompt = Template(prompt_template).substitute(ctext=text)\n",
    "                result = process_gpt(prompt, system_msg=system_msg)\n",
    "                #print(f\"Result: {result}\")  # Debugging: print the result\n",
    "                result_cleaned = re.sub(r'^\\s*```json\\s*|\\s*```\\s*$', '', result.strip())\n",
    "                result_json = json.loads(result_cleaned)\n",
    "                results.append(result_json)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    end = timer()\n",
    "    print(f\"Pipeline completed in {end-start} seconds\")\n",
    "    print(json.dumps(results, indent=4))\n",
    "    return results\n",
    "\n",
    "\n",
    "# Function to take a json-object of entitites and relationships and generate cypher query for creating those entities\n",
    "def generate_cypher(json_obj):\n",
    "    e_statements = []\n",
    "    r_statements = []\n",
    "\n",
    "    e_label_map = {}\n",
    "\n",
    "    # loop through our json object\n",
    "    for i, obj in enumerate(json_obj):\n",
    "        print(f\"Generating cypher for file {i+1} of {len(json_obj)}\")\n",
    "        for entity in obj[\"entities\"]:\n",
    "            label = entity[\"label\"]\n",
    "            id = entity[\"id\"]\n",
    "            id = id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            properties = {k: v for k, v in entity.items() if k not in [\"label\", \"id\"]}\n",
    "\n",
    "            cypher = f'MERGE (n:{label} {{id: \"{id}\"}})'\n",
    "            if properties:\n",
    "                props_str = \", \".join(\n",
    "                    [f'n.{key} = \"{val}\"' for key, val in properties.items()]\n",
    "                )\n",
    "                cypher += f\" ON CREATE SET {props_str}\"\n",
    "            e_statements.append(cypher)\n",
    "            e_label_map[id] = label\n",
    "\n",
    "        for rs in obj[\"relationships\"]:\n",
    "            try:\n",
    "                src_id, rs_type, tgt_id = rs.split(\"|\")\n",
    "                src_id = src_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "                tgt_id = tgt_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "\n",
    "\n",
    "                src_label = e_label_map[src_id]\n",
    "                tgt_label = e_label_map[tgt_id]\n",
    "                cypher = f'MERGE (a:{src_label} {{id: \"{src_id}\"}}) MERGE (b:{tgt_label} {{id: \"{tgt_id}\"}}) MERGE (a)-[:{rs_type}]->(b)'\n",
    "                r_statements.append(cypher)\n",
    "            except (AttributeError, KeyError) as e:\n",
    "                print(f\"Error processing relationship: {rs}. Error: {e}\")\n",
    "\n",
    "    with open(\"cyphers.txt\", \"w\") as outfile:\n",
    "        outfile.write(\"\\n\".join(e_statements + r_statements))\n",
    "\n",
    "    return e_statements + r_statements\n",
    "\n",
    "\n",
    "# Final function to bring all the steps together\n",
    "def ingestion_pipeline(folders):\n",
    "    # Extrating the entites and relationships from each folder, append into one json_object\n",
    "    entities_relationships = []\n",
    "    for key, value in folders.items():\n",
    "        entities_relationships.extend(extract_entities_relationships(key, value))\n",
    "\n",
    "    # Generate and execute cypher statements\n",
    "    cypher_statements = generate_cypher(entities_relationships)\n",
    "    for i, stmt in enumerate(cypher_statements):\n",
    "        print(f\"Executing cypher statement {i+1} of {len(cypher_statements)}\")\n",
    "        try:\n",
    "            gds.execute_query(stmt)\n",
    "        except Exception as e:\n",
    "            with open(\"failed_statements.txt\", \"w\") as f:\n",
    "                f.write(f\"{stmt} - Exception: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for processing project briefs\n",
    "project_prompt_template = \"\"\"\n",
    "From the Project Brief below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. Document must be summarized and stored inside Project entity under `summary` property. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the brief; `id` property is the full name of the project, in lowercase, with no capital letters, special characters, spaces or hyphens; Contents of original document must be summarized inside 'summary' property\n",
    "    label:'Technology',id:string,name:string //Technology Entity; `id` property is the name of the technology, in camel-case. Identify as many of the technologies used as possible\n",
    "    label:'Client',id:string,name:string;industry:string //Client that the project was done for; `id` property is the name of the Client, in camel-case; 'industry' is the industry that the client operates in, as mentioned in the project brief.\n",
    "    \n",
    "2. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    project|USES_TECH|technology \n",
    "    project|HAS_CLIENT|client\n",
    "\n",
    "\n",
    "3. The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Project\",\"id\":string,\"name\":string,\"summary\":string}],\n",
    "    \"relationships\": [\"projectid|USES_TECH|technologyid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompt for processing peoples' profiles\n",
    "people_prompt_template = \"\"\"From the list of people below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,name:string //Person that the data is about. `id` property is the name of the person, in camel-case. 'name' is the person's name, as spelled in the text.\n",
    "    label:'Project',id:string,name:string;summary:string //Project mentioned in the profile; `id` property is the full lowercase name of the project, with no capital letters, special characters, spaces or hyphens.\n",
    "    label:'Technology',id:string,name:string //Technology Entity, as listed in the \"skills\"-section of every person; `id` property is the name of the technology, in camel-case.\n",
    "    \n",
    "3. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    person|HAS_SKILLS|technology \n",
    "    project|HAS_PEOPLE|person\n",
    "\n",
    "\n",
    "The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Person\",\"id\":string,\"name\":string}],\n",
    "    \"relationships\": [\"projectid|HAS_PEOPLE|personid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Prompt for processing slack messages\n",
    "\n",
    "slack_prompt_template = \"\"\"\n",
    "From the list of messages below, extract the following Entities & relationships described in the mentioned format \n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Person',id:string,name:string //Person that sent the message. `id` property is the name of the person, in camel-case; for example, \"michaelClark\", or \"emmaMartinez\"; 'name' is the person's name, as spelled in the text.\n",
    "    label:'SlackMessage',id:string,text:string //The Slack-Message that was sent; 'id' property should be the message id, as spelled in the reference. 'text' property is the text content of the message, as spelled in the reference\n",
    "    \n",
    "3. Next generate each relationships as triples of head, relationship and tail. To refer the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship types:\n",
    "    personid|SENT|slackmessageid\n",
    "\n",
    "The output should look like :\n",
    "{\n",
    "    \"entities\": [{\"label\":\"SlackMessage\",\"id\":string,\"text\":string}],\n",
    "    \"relationships\": [\"personid|SENT|messageid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n",
    "\n",
    "# Prompt for processing technical notes\n",
    "tech_notes_prompt_template = \"\"\"\n",
    "From the Technical Notes below, extract the following Entities & relationships described in the mentioned format\n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses\n",
    "1. First, look for these Entity types in the text and generate as comma-separated format similar to entity type.\n",
    "   `id` property of each entity must be alphanumeric and must be unique among the entities. You will be referring this property to define the relationship between entities. Do not create new entity types that aren't mentioned below. Document must be summarized and stored inside each of the entities under their respective `summary` property. You will have to generate as many entities as needed as per the types below:\n",
    "    Entity Types:\n",
    "    label:'Group', id:string, name:string, summary:string //High-level group; `id` property is the name of the group in camel-case. Use these exact values and no others: Cloud Infrastructure, Application Development, CI/CD, Security, ML and BigData, Cloud Costs, High Availability, Business\n",
    "    label:'SubGroup', id:string, name:string, summary:string //Subgroup under a specific group; `id` is the name in camel-case. Fits under a group, but above the Classifications below.  Example for Infrastructure: ComputerArchitecture, Compute, Databases, Network, Storage\n",
    "    label:'SubGroupClassification', id:string, name:string, summary:string //Classification under a specific subgroup; `id` is the name in camel-case. Use these exact values and no others: Protocols, Services, Frameworks, Concepts\n",
    "    label:'SubGroupConcept', id:string, name:string, summary:string //Concept under a specific subgroup category; `id` is the name in camel-case. Fits under one of the Classification types defined above.  Examples: Routers, Proxies, LoadBalancers, Firewalls, HTTP, DNS, Subnets, TCPIP, OSI-Model\n",
    "\n",
    "2. Next generate each relationship as triples of head, relationship, and tail. To refer to the head and tail entity, use their respective `id` property. Relationship property should be mentioned within brackets as comma-separated. They should follow these relationship types below. You will have to generate as many relationships as needed as defined below:\n",
    "    Relationship Types:\n",
    "    groupid|HAS_SUBGROUP|subgroupid //Indicates that a group has a specific subgroup.\n",
    "    subgroupid|HAS_CATEGORY|subgroupclassificationid //Indicates that a subgroup has a specific classification.\n",
    "    subgroupclassificationid|HAS_CONCEPT|subgroupconceptid //Indicates that a subgroup category has a specific concept.\n",
    "\n",
    "3. The output should be in JSON format without any Markdown or additional formatting. Please provide the output directly as a JSON object.\n",
    "{\n",
    "    \"entities\": [{\"label\":\"Group\",\"id\":string,\"name\":string,\"summary\":string}],\n",
    "    \"relationships\": [\"groupid|HAS_SUBGROUP|subgroupid\"]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running the pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pipeline for 10 files in tech_notes folder\n",
      "Extracting entities and relationships for ./data/tech_notes/technical_requirements_compute.txt\n",
      "Extracting entities and relationships for ./data/tech_notes/database_indexing_strategies.txt\n",
      "Extracting entities and relationships for ./data/tech_notes/availability_vs_reliability.txt\n",
      "Extracting entities and relationships for ./data/tech_notes/technical_storage_additional.txt\n",
      "Extracting entities and relationships for ./data/tech_notes/technical_storage_performance_matrix.txt\n",
      "Extracting entities and relationships for ./data/tech_notes/database_indexing.txt\n",
      "Extracting entities and relationships for ./data/tech_notes/technical_requirements_storage.txt\n",
      "Extracting entities and relationships for ./data/tech_notes/TECHNICAL_REQUIREMENTS_OUTLINE.txt\n",
      "Extracting entities and relationships for ./data/tech_notes/technical_reliability.txt\n",
      "Extracting entities and relationships for ./data/tech_notes/technical_requirements_network.txt\n",
      "Pipeline completed in 187.30354145198362 seconds\n",
      "[\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"CloudInfrastructure\",\n",
      "                \"name\": \"Cloud Infrastructure\",\n",
      "                \"summary\": \"Group related to cloud infrastructure services and components\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"Compute\",\n",
      "                \"name\": \"Compute\",\n",
      "                \"summary\": \"Subgroup related to compute services and use cases\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Services\",\n",
      "                \"name\": \"Services\",\n",
      "                \"summary\": \"Classification under compute services related to different service offerings\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"ComputeEngine\",\n",
      "                \"name\": \"Compute Engine\",\n",
      "                \"summary\": \"Concept under compute services related to specifying and managing virtual machines\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"AppEngine\",\n",
      "                \"name\": \"App Engine\",\n",
      "                \"summary\": \"Concept under compute services related to application deployment and management\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"CloudFunctions\",\n",
      "                \"name\": \"Cloud Functions\",\n",
      "                \"summary\": \"Concept under compute services related to event-driven functions\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"DataFlowPipelines\",\n",
      "                \"name\": \"Data Flow Pipelines\",\n",
      "                \"summary\": \"Subgroup related to data processing pipelines and workflows\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"DataflowPipeline\",\n",
      "                \"name\": \"Dataflow Pipeline\",\n",
      "                \"summary\": \"Concept under data flow pipelines related to data processing using Apache Beam\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Dataproc\",\n",
      "                \"name\": \"Dataproc\",\n",
      "                \"summary\": \"Concept under data flow pipelines related to managed Spark/Hadoop processing\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Workflows\",\n",
      "                \"name\": \"Workflows\",\n",
      "                \"summary\": \"Concept under data flow pipelines related to workflow orchestration\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"ProvisioningCompute\",\n",
      "                \"name\": \"Provisioning Compute\",\n",
      "                \"summary\": \"Subgroup related to infrastructure provisioning using IaC tools\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"ManagingStateWithCompute\",\n",
      "                \"name\": \"Managing State With Compute\",\n",
      "                \"summary\": \"Subgroup related to managing state and data persistence\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"SynchronousAndAsynchronousOperations\",\n",
      "                \"name\": \"Synchronous and Asynchronous Operations\",\n",
      "                \"summary\": \"Concept under managing state with compute related to different operation types\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|Compute\",\n",
      "            \"Compute|HAS_CATEGORY|Services\",\n",
      "            \"Services|HAS_CONCEPT|ComputeEngine\",\n",
      "            \"Services|HAS_CONCEPT|AppEngine\",\n",
      "            \"Services|HAS_CONCEPT|CloudFunctions\",\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|DataFlowPipelines\",\n",
      "            \"DataFlowPipelines|HAS_CONCEPT|DataflowPipeline\",\n",
      "            \"DataFlowPipelines|HAS_CONCEPT|Dataproc\",\n",
      "            \"DataFlowPipelines|HAS_CONCEPT|Workflows\",\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|ProvisioningCompute\",\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|ManagingStateWithCompute\",\n",
      "            \"ManagingStateWithCompute|HAS_CONCEPT|SynchronousAndAsynchronousOperations\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"CloudInfrastructure\",\n",
      "                \"name\": \"Cloud Infrastructure\",\n",
      "                \"summary\": \"High-level group for cloud infrastructure technologies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"Databases\",\n",
      "                \"name\": \"Databases\",\n",
      "                \"summary\": \"Subgroup under Cloud Infrastructure focusing on database technologies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Protocols\",\n",
      "                \"name\": \"Protocols\",\n",
      "                \"summary\": \"Classification under Databases subgroup for protocol technologies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Routers\",\n",
      "                \"name\": \"Routers\",\n",
      "                \"summary\": \"Concept under Protocols classification for router technologies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"ApplicationDevelopment\",\n",
      "                \"name\": \"Application Development\",\n",
      "                \"summary\": \"High-level group for application development technologies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"BigTable\",\n",
      "                \"name\": \"BigTable\",\n",
      "                \"summary\": \"Subgroup under Application Development focusing on BigTable technology.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Concepts\",\n",
      "                \"name\": \"Concepts\",\n",
      "                \"summary\": \"Classification under BigTable subgroup for concept technologies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"RowKeyPartitioning\",\n",
      "                \"name\": \"Row Key Partitioning\",\n",
      "                \"summary\": \"Concept under Concepts classification for row key partitioning techniques.\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|Databases\",\n",
      "            \"Databases|HAS_CATEGORY|Protocols\",\n",
      "            \"Protocols|HAS_CONCEPT|Routers\",\n",
      "            \"ApplicationDevelopment|HAS_SUBGROUP|BigTable\",\n",
      "            \"BigTable|HAS_CATEGORY|Concepts\",\n",
      "            \"Concepts|HAS_CONCEPT|RowKeyPartitioning\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"HighAvailability\",\n",
      "                \"name\": \"High Availability\",\n",
      "                \"summary\": \"Group related to ensuring high availability of systems and services.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"Availability\",\n",
      "                \"name\": \"Availability\",\n",
      "                \"summary\": \"Subgroup focusing on measuring the ability of equipment to be operational when needed.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Metrics\",\n",
      "                \"name\": \"Metrics\",\n",
      "                \"summary\": \"Classification under Availability subgroup for measuring uptime and operational performance.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"PercentAvailable\",\n",
      "                \"name\": \"Percent Available\",\n",
      "                \"summary\": \"Concept under Metrics classification for calculating the percentage of time an asset is available.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"MeanTimeBetweenFailures\",\n",
      "                \"name\": \"Mean Time Between Failures\",\n",
      "                \"summary\": \"Concept under Metrics classification for calculating the average time between failures.\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"HighAvailability|HAS_SUBGROUP|Availability\",\n",
      "            \"Availability|HAS_CATEGORY|Metrics\",\n",
      "            \"Metrics|HAS_CONCEPT|PercentAvailable\",\n",
      "            \"Metrics|HAS_CONCEPT|MeanTimeBetweenFailures\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"CloudInfrastructure\",\n",
      "                \"name\": \"Cloud Infrastructure\",\n",
      "                \"summary\": \"High-level group for cloud infrastructure technologies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"BlockStorage\",\n",
      "                \"name\": \"Block Storage\",\n",
      "                \"summary\": \"Subgroup under Cloud Infrastructure for block storage technologies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"PersistentStorage\",\n",
      "                \"name\": \"Persistent Storage\",\n",
      "                \"summary\": \"Classification under Block Storage for persistent storage solutions.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"PersistentDisk\",\n",
      "                \"name\": \"Persistent Disk\",\n",
      "                \"summary\": \"Concept under Persistent Storage for persistent disk storage.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"ObjectStorage\",\n",
      "                \"name\": \"Object Storage\",\n",
      "                \"summary\": \"High-level group for object storage technologies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"CloudStorage\",\n",
      "                \"name\": \"Cloud Storage\",\n",
      "                \"summary\": \"Subgroup under Object Storage for cloud storage solutions.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"CloudStorageClasses\",\n",
      "                \"name\": \"Cloud Storage Classes\",\n",
      "                \"summary\": \"Classification under Cloud Storage for different classes of cloud storage.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"VersioningLifecycle\",\n",
      "                \"name\": \"Versioning and Lifecycle Management\",\n",
      "                \"summary\": \"Concept under Cloud Storage Classes for managing object versions and lifecycle.\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|BlockStorage\",\n",
      "            \"BlockStorage|HAS_CATEGORY|PersistentStorage\",\n",
      "            \"PersistentStorage|HAS_CONCEPT|PersistentDisk\",\n",
      "            \"ObjectStorage|HAS_SUBGROUP|CloudStorage\",\n",
      "            \"CloudStorage|HAS_CATEGORY|CloudStorageClasses\",\n",
      "            \"CloudStorageClasses|HAS_CONCEPT|VersioningLifecycle\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"CloudInfrastructure\",\n",
      "                \"name\": \"Cloud Infrastructure\",\n",
      "                \"summary\": \"Information related to cloud storage, local SSD, object storage, and file storage.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"Storage\",\n",
      "                \"name\": \"Storage\",\n",
      "                \"summary\": \"Details about persistent HDD, SSD, local SSD, object storage, and file storage.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Performance\",\n",
      "                \"name\": \"Performance\",\n",
      "                \"summary\": \"Performance metrics of different storage types.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"StoragePerformanceMetrics\",\n",
      "                \"name\": \"Storage Performance Metrics\",\n",
      "                \"summary\": \"Detailed performance metrics of storage types including IOPs, throughput, latency, and durability.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"ApplicationDevelopment\",\n",
      "                \"name\": \"Application Development\",\n",
      "                \"summary\": \"Information related to databases like Cloud SQL, Spanner, BigQuery, Bigtable, and Firestore.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"Databases\",\n",
      "                \"name\": \"Databases\",\n",
      "                \"summary\": \"Details about different database services like Cloud SQL, Spanner, BigQuery, Bigtable, and Firestore.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"DatabasePerformance\",\n",
      "                \"name\": \"Database Performance\",\n",
      "                \"summary\": \"Performance metrics and capabilities of various databases.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"DatabaseFeatures\",\n",
      "                \"name\": \"Database Features\",\n",
      "                \"summary\": \"Features and functionalities of different databases like Cloud SQL, Spanner, BigQuery, Bigtable, and Firestore.\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|Storage\",\n",
      "            \"Storage|HAS_CATEGORY|Performance\",\n",
      "            \"Performance|HAS_CONCEPT|StoragePerformanceMetrics\",\n",
      "            \"ApplicationDevelopment|HAS_SUBGROUP|Databases\",\n",
      "            \"Databases|HAS_CATEGORY|DatabasePerformance\",\n",
      "            \"DatabasePerformance|HAS_CONCEPT|DatabaseFeatures\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"compute\",\n",
      "                \"name\": \"Compute\",\n",
      "                \"summary\": \"Subgroup under Cloud Infrastructure related to compute resources.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"services\",\n",
      "                \"name\": \"Services\",\n",
      "                \"summary\": \"Classification under Compute subgroup related to services.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"indexing\",\n",
      "                \"name\": \"Indexing\",\n",
      "                \"summary\": \"Concept under Services classification related to indexing capabilities.\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"compute|HAS_CATEGORY|services\",\n",
      "            \"services|HAS_CONCEPT|indexing\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"CloudInfrastructure\",\n",
      "                \"name\": \"Cloud Infrastructure\",\n",
      "                \"summary\": \"Storage systems, cloud storage, cloud filestore, caching with cloud memorystore, retention, lifecycle management in cloud storage, networking and latency\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"ObjectStorage\",\n",
      "                \"name\": \"Object Storage\",\n",
      "                \"summary\": \"Unstructured data storage, buckets, access controls, cloud storage as a filesystem, storage tiers, availability, use cases\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"BigQuery\",\n",
      "                \"name\": \"BigQuery\",\n",
      "                \"summary\": \"Columnar format, jobs, datasets, billing, IAM roles, loading data, storage write API\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"ColumnarFormat\",\n",
      "                \"name\": \"Columnar Format\",\n",
      "                \"summary\": \"Data stored in columns, supports nested and repeated fields\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Jobs\",\n",
      "                \"name\": \"Jobs\",\n",
      "                \"summary\": \"Tasks execution like loading and exporting data, running queries\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Datasets\",\n",
      "                \"name\": \"Datasets\",\n",
      "                \"summary\": \"Organize tables and views, regional or multi-regional\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"CloudMemoryStore\",\n",
      "                \"name\": \"Cloud MemoryStore\",\n",
      "                \"summary\": \"Managed cache service, Redis, Memcached, use cases, architecture\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"BigTable\",\n",
      "                \"name\": \"BigTable\",\n",
      "                \"summary\": \"Wide column NoSQL, structure, analytics and operational use cases\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"WideColumnNoSQL\",\n",
      "                \"name\": \"Wide Column NoSQL\",\n",
      "                \"summary\": \"Columns grouped into column families, tablets, multiple clusters\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Datastore\",\n",
      "                \"name\": \"Datastore\",\n",
      "                \"summary\": \"Document NoSQL database, consistency, naming, applications\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"DocumentNoSQL\",\n",
      "                \"name\": \"Document NoSQL\",\n",
      "                \"summary\": \"Flexible JSON-like data structure, document, entity, property, key\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Firestore\",\n",
      "                \"name\": \"Firestore\",\n",
      "                \"summary\": \"Next generation document NoSQL database, consistency, server-based projects, web and mobile applications\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"NextGenDocumentNoSQL\",\n",
      "                \"name\": \"Next Generation Document NoSQL\",\n",
      "                \"summary\": \"Flexible JSON-like data structure, document\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|ObjectStorage\",\n",
      "            \"ObjectStorage|HAS_CATEGORY|BigQuery\",\n",
      "            \"BigQuery|HAS_CONCEPT|ColumnarFormat\",\n",
      "            \"BigQuery|HAS_CONCEPT|Jobs\",\n",
      "            \"BigQuery|HAS_CONCEPT|Datasets\",\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|CloudMemoryStore\",\n",
      "            \"CloudMemoryStore|HAS_CATEGORY|BigTable\",\n",
      "            \"BigTable|HAS_CONCEPT|WideColumnNoSQL\",\n",
      "            \"CloudMemoryStore|HAS_CATEGORY|Datastore\",\n",
      "            \"Datastore|HAS_CONCEPT|DocumentNoSQL\",\n",
      "            \"CloudMemoryStore|HAS_CATEGORY|Firestore\",\n",
      "            \"Firestore|HAS_CONCEPT|NextGenDocumentNoSQL\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"CloudInfrastructure\",\n",
      "                \"name\": \"Cloud Infrastructure\",\n",
      "                \"summary\": \"High-level group for cloud infrastructure concepts and technologies\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"Compute\",\n",
      "                \"name\": \"Compute\",\n",
      "                \"summary\": \"Subgroup under Cloud Infrastructure focusing on compute resources\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Protocols\",\n",
      "                \"name\": \"Protocols\",\n",
      "                \"summary\": \"Classification under Compute subgroup for protocols\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"HTTP\",\n",
      "                \"name\": \"HTTP\",\n",
      "                \"summary\": \"Concept under Protocols classification for HTTP protocol\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"HighAvailability\",\n",
      "                \"name\": \"High Availability\",\n",
      "                \"summary\": \"High-level group for high availability concepts and technologies\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"Storage\",\n",
      "                \"name\": \"Storage\",\n",
      "                \"summary\": \"Subgroup under High Availability focusing on storage technologies\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"PersistentDisks\",\n",
      "                \"name\": \"Persistent Disks\",\n",
      "                \"summary\": \"Classification under Storage subgroup for persistent disk technologies\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"LocalSSD\",\n",
      "                \"name\": \"Local SSD\",\n",
      "                \"summary\": \"Concept under Persistent Disks classification for local SSD storage\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|Compute\",\n",
      "            \"Compute|HAS_CATEGORY|Protocols\",\n",
      "            \"Protocols|HAS_CONCEPT|HTTP\",\n",
      "            \"HighAvailability|HAS_SUBGROUP|Storage\",\n",
      "            \"Storage|HAS_CATEGORY|PersistentDisks\",\n",
      "            \"PersistentDisks|HAS_CONCEPT|LocalSSD\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"CloudInfrastructure\",\n",
      "                \"name\": \"Cloud Infrastructure\",\n",
      "                \"summary\": \"Group related to cloud infrastructure operations and monitoring.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"CloudMonitoring\",\n",
      "                \"name\": \"Cloud Monitoring\",\n",
      "                \"summary\": \"Subgroup under Cloud Infrastructure focusing on monitoring metrics and logging.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Metrics\",\n",
      "                \"name\": \"Metrics\",\n",
      "                \"summary\": \"Classification under Cloud Monitoring for metrics monitoring.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"CPU\",\n",
      "                \"name\": \"CPU\",\n",
      "                \"summary\": \"Concept related to monitoring CPU performance.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Memory\",\n",
      "                \"name\": \"Memory\",\n",
      "                \"summary\": \"Concept related to monitoring memory usage.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Disk\",\n",
      "                \"name\": \"Disk\",\n",
      "                \"summary\": \"Concept related to monitoring disk storage.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"TimeSeries\",\n",
      "                \"name\": \"Time Series\",\n",
      "                \"summary\": \"Classification under Cloud Monitoring for time-stamped metrics.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"CloudLogging\",\n",
      "                \"name\": \"Cloud Logging\",\n",
      "                \"summary\": \"Subgroup under Cloud Infrastructure focusing on logging and log analytics.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Logs\",\n",
      "                \"name\": \"Logs\",\n",
      "                \"summary\": \"Concept related to logging events and activities.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"LogAnalytics\",\n",
      "                \"name\": \"Log Analytics\",\n",
      "                \"summary\": \"Concept related to analyzing logs for insights.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"OpenSourceObservabilityTools\",\n",
      "                \"name\": \"Open Source Observability Tools\",\n",
      "                \"summary\": \"Subgroup under Cloud Infrastructure for open-source monitoring tools.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Prometheus\",\n",
      "                \"name\": \"Prometheus\",\n",
      "                \"summary\": \"Concept related to open-source monitoring tool Prometheus.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Grafana\",\n",
      "                \"name\": \"Grafana\",\n",
      "                \"summary\": \"Concept related to open-source monitoring tool Grafana.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"ApplicationDevelopment\",\n",
      "                \"name\": \"Application Development\",\n",
      "                \"summary\": \"Group related to application development tools and practices.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"ReleaseManagement\",\n",
      "                \"name\": \"Release Management\",\n",
      "                \"summary\": \"Subgroup under Application Development focusing on code deployment and release strategies.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"ContinuousDelivery\",\n",
      "                \"name\": \"Continuous Delivery\",\n",
      "                \"summary\": \"Subgroup under Release Management for automated code publishing.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"UnitTest\",\n",
      "                \"name\": \"Unit Test\",\n",
      "                \"summary\": \"Concept related to unit testing code components.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"IntegrationTest\",\n",
      "                \"name\": \"Integration Test\",\n",
      "                \"summary\": \"Concept related to testing component interactions.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"AcceptanceTest\",\n",
      "                \"name\": \"Acceptance Test\",\n",
      "                \"summary\": \"Concept related to testing code acceptance criteria.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"LoadTest\",\n",
      "                \"name\": \"Load Test\",\n",
      "                \"summary\": \"Concept related to testing system performance under load.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"ContinuousIntegration\",\n",
      "                \"name\": \"Continuous Integration\",\n",
      "                \"summary\": \"Subgroup under Release Management for code integration practices.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"SystemsReliabilityEngineering\",\n",
      "                \"name\": \"Systems Reliability Engineering\",\n",
      "                \"summary\": \"Group focusing on system reliability and failure management.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"ExcessiveLoads\",\n",
      "                \"name\": \"Excessive Loads\",\n",
      "                \"summary\": \"Concept related to managing high traffic loads.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"CascadingFailures\",\n",
      "                \"name\": \"Cascading Failures\",\n",
      "                \"summary\": \"Concept related to handling failures that propagate through a system.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"IncidentManagement\",\n",
      "                \"name\": \"Incident Management\",\n",
      "                \"summary\": \"Concept related to managing service disruptions and post-incident analysis.\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|CloudMonitoring\",\n",
      "            \"CloudMonitoring|HAS_CATEGORY|Metrics\",\n",
      "            \"CloudMonitoring|HAS_CATEGORY|TimeSeries\",\n",
      "            \"CloudMonitoring|HAS_CATEGORY|LogAnalytics\",\n",
      "            \"CloudMonitoring|HAS_CONCEPT|CPU\",\n",
      "            \"CloudMonitoring|HAS_CONCEPT|Memory\",\n",
      "            \"CloudMonitoring|HAS_CONCEPT|Disk\",\n",
      "            \"CloudLogging|HAS_CONCEPT|Logs\",\n",
      "            \"OpenSourceObservabilityTools|HAS_CONCEPT|Prometheus\",\n",
      "            \"OpenSourceObservabilityTools|HAS_CONCEPT|Grafana\",\n",
      "            \"ApplicationDevelopment|HAS_SUBGROUP|ReleaseManagement\",\n",
      "            \"ReleaseManagement|HAS_SUBGROUP|ContinuousDelivery\",\n",
      "            \"ContinuousDelivery|HAS_CATEGORY|UnitTest\",\n",
      "            \"ContinuousDelivery|HAS_CATEGORY|IntegrationTest\",\n",
      "            \"ContinuousDelivery|HAS_CATEGORY|AcceptanceTest\",\n",
      "            \"ContinuousDelivery|HAS_CATEGORY|LoadTest\",\n",
      "            \"ReleaseManagement|HAS_SUBGROUP|ContinuousIntegration\",\n",
      "            \"SystemsReliabilityEngineering|HAS_SUBGROUP|ExcessiveLoads\",\n",
      "            \"SystemsReliabilityEngineering|HAS_SUBGROUP|CascadingFailures\",\n",
      "            \"SystemsReliabilityEngineering|HAS_SUBGROUP|IncidentManagement\"\n",
      "        ]\n",
      "    },\n",
      "    {\n",
      "        \"entities\": [\n",
      "            {\n",
      "                \"label\": \"Group\",\n",
      "                \"id\": \"CloudInfrastructure\",\n",
      "                \"name\": \"Cloud Infrastructure\",\n",
      "                \"summary\": \"High-level group for cloud infrastructure concepts and services.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroup\",\n",
      "                \"id\": \"Networking\",\n",
      "                \"name\": \"Networking\",\n",
      "                \"summary\": \"Subgroup under Cloud Infrastructure focusing on networking concepts.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupClassification\",\n",
      "                \"id\": \"Protocols\",\n",
      "                \"name\": \"Protocols\",\n",
      "                \"summary\": \"Classification under Networking for various network protocols.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"IPAddressing\",\n",
      "                \"name\": \"IP Addressing\",\n",
      "                \"summary\": \"Concept under Protocols for understanding CIDR addressing.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"FirewallRules\",\n",
      "                \"name\": \"Firewall Rules\",\n",
      "                \"summary\": \"Concept under Protocols for managing firewall rules.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"Routers\",\n",
      "                \"name\": \"Routers\",\n",
      "                \"summary\": \"Concept under Protocols for controlling traffic using routers.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"CloudArmor\",\n",
      "                \"name\": \"Cloud Armor\",\n",
      "                \"summary\": \"Concept under Protocols for layer 7 web application firewall.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"VPCs\",\n",
      "                \"name\": \"VPCs\",\n",
      "                \"summary\": \"Concept under Protocols for understanding Virtual Private Clouds.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"SharedVPC\",\n",
      "                \"name\": \"Shared VPC\",\n",
      "                \"summary\": \"Concept under Protocols for shared Virtual Private Clouds.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"VPCNetworkPeering\",\n",
      "                \"name\": \"VPC Network Peering\",\n",
      "                \"summary\": \"Concept under Protocols for connecting VPC networks.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"HybridCloudNetworking\",\n",
      "                \"name\": \"Hybrid Cloud Networking\",\n",
      "                \"summary\": \"Concept under Protocols for networking between on-prem and cloud.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"ServiceCentricNetworking\",\n",
      "                \"name\": \"Service-Centric Networking\",\n",
      "                \"summary\": \"Concept under Protocols for service-oriented networking.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"LoadBalancing\",\n",
      "                \"name\": \"Load Balancing\",\n",
      "                \"summary\": \"Concept under Protocols for balancing network loads.\"\n",
      "            },\n",
      "            {\n",
      "                \"label\": \"SubGroupConcept\",\n",
      "                \"id\": \"AdditionalNetworkServices\",\n",
      "                \"name\": \"Additional Network Services\",\n",
      "                \"summary\": \"Concept under Protocols for additional network-related services.\"\n",
      "            }\n",
      "        ],\n",
      "        \"relationships\": [\n",
      "            \"CloudInfrastructure|HAS_SUBGROUP|Networking\",\n",
      "            \"Networking|HAS_CATEGORY|Protocols\",\n",
      "            \"Protocols|HAS_CONCEPT|IPAddressing\",\n",
      "            \"Protocols|HAS_CONCEPT|FirewallRules\",\n",
      "            \"Protocols|HAS_CONCEPT|Routers\",\n",
      "            \"Protocols|HAS_CONCEPT|CloudArmor\",\n",
      "            \"Protocols|HAS_CONCEPT|VPCs\",\n",
      "            \"Protocols|HAS_CONCEPT|SharedVPC\",\n",
      "            \"Protocols|HAS_CONCEPT|VPCNetworkPeering\",\n",
      "            \"Protocols|HAS_CONCEPT|HybridCloudNetworking\",\n",
      "            \"Protocols|HAS_CONCEPT|ServiceCentricNetworking\",\n",
      "            \"Protocols|HAS_CONCEPT|LoadBalancing\",\n",
      "            \"Protocols|HAS_CONCEPT|AdditionalNetworkServices\"\n",
      "        ]\n",
      "    }\n",
      "]\n",
      "Generating cypher for file 1 of 10\n",
      "Generating cypher for file 2 of 10\n",
      "Generating cypher for file 3 of 10\n",
      "Generating cypher for file 4 of 10\n",
      "Generating cypher for file 5 of 10\n",
      "Generating cypher for file 6 of 10\n",
      "Generating cypher for file 7 of 10\n",
      "Generating cypher for file 8 of 10\n",
      "Generating cypher for file 9 of 10\n",
      "Generating cypher for file 10 of 10\n",
      "Executing cypher statement 1 of 192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to read from defunct connection ResolvedIPv4Address(('34.121.155.65', 7687)) (ResolvedIPv4Address(('34.121.155.65', 7687)))\n",
      "Unable to retrieve routing information\n",
      "Transaction failed and will be retried in 0.9845391744607744s (Unable to retrieve routing information)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing cypher statement 2 of 192\n",
      "Executing cypher statement 3 of 192\n",
      "Executing cypher statement 4 of 192\n",
      "Executing cypher statement 5 of 192\n",
      "Executing cypher statement 6 of 192\n",
      "Executing cypher statement 7 of 192\n",
      "Executing cypher statement 8 of 192\n",
      "Executing cypher statement 9 of 192\n",
      "Executing cypher statement 10 of 192\n",
      "Executing cypher statement 11 of 192\n",
      "Executing cypher statement 12 of 192\n",
      "Executing cypher statement 13 of 192\n",
      "Executing cypher statement 14 of 192\n",
      "Executing cypher statement 15 of 192\n",
      "Executing cypher statement 16 of 192\n",
      "Executing cypher statement 17 of 192\n",
      "Executing cypher statement 18 of 192\n",
      "Executing cypher statement 19 of 192\n",
      "Executing cypher statement 20 of 192\n",
      "Executing cypher statement 21 of 192\n",
      "Executing cypher statement 22 of 192\n",
      "Executing cypher statement 23 of 192\n",
      "Executing cypher statement 24 of 192\n",
      "Executing cypher statement 25 of 192\n",
      "Executing cypher statement 26 of 192\n",
      "Executing cypher statement 27 of 192\n",
      "Executing cypher statement 28 of 192\n",
      "Executing cypher statement 29 of 192\n",
      "Executing cypher statement 30 of 192\n",
      "Executing cypher statement 31 of 192\n",
      "Executing cypher statement 32 of 192\n",
      "Executing cypher statement 33 of 192\n",
      "Executing cypher statement 34 of 192\n",
      "Executing cypher statement 35 of 192\n",
      "Executing cypher statement 36 of 192\n",
      "Executing cypher statement 37 of 192\n",
      "Executing cypher statement 38 of 192\n",
      "Executing cypher statement 39 of 192\n",
      "Executing cypher statement 40 of 192\n",
      "Executing cypher statement 41 of 192\n",
      "Executing cypher statement 42 of 192\n",
      "Executing cypher statement 43 of 192\n",
      "Executing cypher statement 44 of 192\n",
      "Executing cypher statement 45 of 192\n",
      "Executing cypher statement 46 of 192\n",
      "Executing cypher statement 47 of 192\n",
      "Executing cypher statement 48 of 192\n",
      "Executing cypher statement 49 of 192\n",
      "Executing cypher statement 50 of 192\n",
      "Executing cypher statement 51 of 192\n",
      "Executing cypher statement 52 of 192\n",
      "Executing cypher statement 53 of 192\n",
      "Executing cypher statement 54 of 192\n",
      "Executing cypher statement 55 of 192\n",
      "Executing cypher statement 56 of 192\n",
      "Executing cypher statement 57 of 192\n",
      "Executing cypher statement 58 of 192\n",
      "Executing cypher statement 59 of 192\n",
      "Executing cypher statement 60 of 192\n",
      "Executing cypher statement 61 of 192\n",
      "Executing cypher statement 62 of 192\n",
      "Executing cypher statement 63 of 192\n",
      "Executing cypher statement 64 of 192\n",
      "Executing cypher statement 65 of 192\n",
      "Executing cypher statement 66 of 192\n",
      "Executing cypher statement 67 of 192\n",
      "Executing cypher statement 68 of 192\n",
      "Executing cypher statement 69 of 192\n",
      "Executing cypher statement 70 of 192\n",
      "Executing cypher statement 71 of 192\n",
      "Executing cypher statement 72 of 192\n",
      "Executing cypher statement 73 of 192\n",
      "Executing cypher statement 74 of 192\n",
      "Executing cypher statement 75 of 192\n",
      "Executing cypher statement 76 of 192\n",
      "Executing cypher statement 77 of 192\n",
      "Executing cypher statement 78 of 192\n",
      "Executing cypher statement 79 of 192\n",
      "Executing cypher statement 80 of 192\n",
      "Executing cypher statement 81 of 192\n",
      "Executing cypher statement 82 of 192\n",
      "Executing cypher statement 83 of 192\n",
      "Executing cypher statement 84 of 192\n",
      "Executing cypher statement 85 of 192\n",
      "Executing cypher statement 86 of 192\n",
      "Executing cypher statement 87 of 192\n",
      "Executing cypher statement 88 of 192\n",
      "Executing cypher statement 89 of 192\n",
      "Executing cypher statement 90 of 192\n",
      "Executing cypher statement 91 of 192\n",
      "Executing cypher statement 92 of 192\n",
      "Executing cypher statement 93 of 192\n",
      "Executing cypher statement 94 of 192\n",
      "Executing cypher statement 95 of 192\n",
      "Executing cypher statement 96 of 192\n",
      "Executing cypher statement 97 of 192\n",
      "Executing cypher statement 98 of 192\n",
      "Executing cypher statement 99 of 192\n",
      "Executing cypher statement 100 of 192\n",
      "Executing cypher statement 101 of 192\n",
      "Executing cypher statement 102 of 192\n",
      "Executing cypher statement 103 of 192\n",
      "Executing cypher statement 104 of 192\n",
      "Executing cypher statement 105 of 192\n",
      "Executing cypher statement 106 of 192\n",
      "Executing cypher statement 107 of 192\n",
      "Executing cypher statement 108 of 192\n",
      "Executing cypher statement 109 of 192\n",
      "Executing cypher statement 110 of 192\n",
      "Executing cypher statement 111 of 192\n",
      "Executing cypher statement 112 of 192\n",
      "Executing cypher statement 113 of 192\n",
      "Executing cypher statement 114 of 192\n",
      "Executing cypher statement 115 of 192\n",
      "Executing cypher statement 116 of 192\n",
      "Executing cypher statement 117 of 192\n",
      "Executing cypher statement 118 of 192\n",
      "Executing cypher statement 119 of 192\n",
      "Executing cypher statement 120 of 192\n",
      "Executing cypher statement 121 of 192\n",
      "Executing cypher statement 122 of 192\n",
      "Executing cypher statement 123 of 192\n",
      "Executing cypher statement 124 of 192\n",
      "Executing cypher statement 125 of 192\n",
      "Executing cypher statement 126 of 192\n",
      "Executing cypher statement 127 of 192\n",
      "Executing cypher statement 128 of 192\n",
      "Executing cypher statement 129 of 192\n",
      "Executing cypher statement 130 of 192\n",
      "Executing cypher statement 131 of 192\n",
      "Executing cypher statement 132 of 192\n",
      "Executing cypher statement 133 of 192\n",
      "Executing cypher statement 134 of 192\n",
      "Executing cypher statement 135 of 192\n",
      "Executing cypher statement 136 of 192\n",
      "Executing cypher statement 137 of 192\n",
      "Executing cypher statement 138 of 192\n",
      "Executing cypher statement 139 of 192\n",
      "Executing cypher statement 140 of 192\n",
      "Executing cypher statement 141 of 192\n",
      "Executing cypher statement 142 of 192\n",
      "Executing cypher statement 143 of 192\n",
      "Executing cypher statement 144 of 192\n",
      "Executing cypher statement 145 of 192\n",
      "Executing cypher statement 146 of 192\n",
      "Executing cypher statement 147 of 192\n",
      "Executing cypher statement 148 of 192\n",
      "Executing cypher statement 149 of 192\n",
      "Executing cypher statement 150 of 192\n",
      "Executing cypher statement 151 of 192\n",
      "Executing cypher statement 152 of 192\n",
      "Executing cypher statement 153 of 192\n",
      "Executing cypher statement 154 of 192\n",
      "Executing cypher statement 155 of 192\n",
      "Executing cypher statement 156 of 192\n",
      "Executing cypher statement 157 of 192\n",
      "Executing cypher statement 158 of 192\n",
      "Executing cypher statement 159 of 192\n",
      "Executing cypher statement 160 of 192\n",
      "Executing cypher statement 161 of 192\n",
      "Executing cypher statement 162 of 192\n",
      "Executing cypher statement 163 of 192\n",
      "Executing cypher statement 164 of 192\n",
      "Executing cypher statement 165 of 192\n",
      "Executing cypher statement 166 of 192\n",
      "Executing cypher statement 167 of 192\n",
      "Executing cypher statement 168 of 192\n",
      "Executing cypher statement 169 of 192\n",
      "Executing cypher statement 170 of 192\n",
      "Executing cypher statement 171 of 192\n",
      "Executing cypher statement 172 of 192\n",
      "Executing cypher statement 173 of 192\n",
      "Executing cypher statement 174 of 192\n",
      "Executing cypher statement 175 of 192\n",
      "Executing cypher statement 176 of 192\n",
      "Executing cypher statement 177 of 192\n",
      "Executing cypher statement 178 of 192\n",
      "Executing cypher statement 179 of 192\n",
      "Executing cypher statement 180 of 192\n",
      "Executing cypher statement 181 of 192\n",
      "Executing cypher statement 182 of 192\n",
      "Executing cypher statement 183 of 192\n",
      "Executing cypher statement 184 of 192\n",
      "Executing cypher statement 185 of 192\n",
      "Executing cypher statement 186 of 192\n",
      "Executing cypher statement 187 of 192\n",
      "Executing cypher statement 188 of 192\n",
      "Executing cypher statement 189 of 192\n",
      "Executing cypher statement 190 of 192\n",
      "Executing cypher statement 191 of 192\n",
      "Executing cypher statement 192 of 192\n"
     ]
    }
   ],
   "source": [
    "folders = {\n",
    "    # \"people_profiles\": people_prompt_template,\n",
    "    # \"project_briefs\": project_prompt_template,\n",
    "    # \"slack_messages\": slack_prompt_template,\n",
    "    \"tech_notes\": tech_notes_prompt_template,\n",
    "}\n",
    "\n",
    "ingestion_pipeline(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
